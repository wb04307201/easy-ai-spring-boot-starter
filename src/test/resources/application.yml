spring:
  application:
    name: spring_ai_demo
  ai:
    ollama:
      chat:
        options:
          model: llama3
      embedding:
        options:
          model: llama3
      base-url: "http://localhost:11434"
    vectorstore:
      chroma:
        client:
          host: http://localhost
          port: 8000
        store:
          collection-name: SpringAiCollection

logging:
  level:
    root: debug
